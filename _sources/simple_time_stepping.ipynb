{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple time-stepping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous examples were all stationary problems. However, many practical simulations describe processes that change over time. In this part we want to start looking a bit closer onto time-domain partial differential equations and their efficient implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Difference Approximation for the time-derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to approximate the derivative $\\frac{du}{dt}$. Remember that\n",
    "\n",
    "$$\n",
    "\\frac{du}{dt} \\approx \\frac{u(t+\\Delta t) - u(t)}{\\Delta t}\n",
    "$$\n",
    "\n",
    "for sufficiently small $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three standard approximations for the time-derivative:\n",
    "\n",
    "* The forward difference: \n",
    "\n",
    "$$\n",
    "\\frac{du}{dt}\\approx \\frac{u(t + \\Delta t) - u(t)}{\\Delta t}.\n",
    "$$\n",
    "\n",
    "* The backward difference: \n",
    "\n",
    "$$\n",
    "\\frac{du}{dt}\\approx \\frac{u(t) - u(t - \\Delta t)}{\\Delta t}.\n",
    "$$\n",
    "\n",
    "* The centered difference: \n",
    "\n",
    "$$\n",
    "\\frac{du}{dt} \\approx \\frac{u(t + \\Delta t) - u(t -\\Delta t)}{2\\Delta t}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the error of these schemes we can use Tayler expansions to obtain\n",
    "\n",
    "$$\n",
    "\\frac{u(t + \\Delta t) - u(t)}{\\Delta t} = u'(t) + \\frac{1}{2}\\Delta tu''(t) + \\dots\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{u(t) - u(t-\\Delta t)}{\\Delta t} = u'(t) - \\frac{1}{2}\\Delta t u''(t) + \\dots\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{u(t + \\Delta t) - u(t-\\Delta t)}{2\\Delta t} = u'(t) + \\frac{1}{6}\\Delta t^2u'''(t) + \\dots\n",
    "$$\n",
    "\n",
    "Hence, the error of the first two schemes decreases linearly with $h$ and the error in the centred scheme decreases quadratically with $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3-point stencil for the second derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we denote $u_i := u(t)$, $u_{i + 1} := u(t + h)$, $u_{i-1} := u(t - h)$. We want to approximate\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\left[\\frac{du}{dt}\\right].\n",
    "$$\n",
    "\n",
    "The trick is to use an approximation around half-steps for the outer derivative, resulting in\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt}\\left[\\frac{du}{dt}\\right]\\approx \\frac{1}{\\Delta t}\\left[{u_{i+\\frac{1}{2}}'} - {u_{i-\\frac{1}{2}}'}\\right].\n",
    "$$\n",
    "\n",
    "The derivatives at the half-steps are now again approximated by centered differences, resulting in\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dt}\\left[\\frac{du}{dt}\\right]&\\approx \\frac{1}{\\Delta t}\\left[\\frac{u_{i+1} - u_i}{h} - \\frac{u_i - u_{i-1}}{\\Delta t}\\right]\\\\\n",
    "&= \\frac{u_{i+1} - 2u_i + u_{i-1}}{\\Delta t^2}\\\\\n",
    "&= u''(t) + \\mathcal{O}(\\Delta t^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This is the famous second order finite difference operator that we have already used before. Its error is quadratically small in $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to time-dependent problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to solve\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dU}{dt} &= f(U, t)\\\\\n",
    "         U(0) &= U_0,\n",
    "\\end{align}\n",
    "$$\n",
    "where $U(t):\\mathbb{R}\\rightarrow \\mathbb{R}^n$ is some vector valued function.\n",
    "\n",
    "The idea is replace $\\frac{dU}{dt}$ by a finite difference approximation.\n",
    "\n",
    "* Forward Euler Method\n",
    "\n",
    "$$\n",
    "\\frac{U_{n+1} - U_n}{\\Delta t} = f(U_n, t_n)\n",
    "$$\n",
    "\n",
    "* Backward Euler Method\n",
    "\n",
    "$$\n",
    "\\frac{U_{n+1} - U_n}{\\Delta t} = f(U_{n+1}, t_{n+1})\n",
    "$$\n",
    "\n",
    "The forward Euler method is an explicit method. We have that\n",
    "\n",
    "$$\n",
    "U_{n+1} = U_n + \\Delta tf(U_n, t_n).\n",
    "$$\n",
    "\n",
    "and the right-hand side only has known values.\n",
    "\n",
    "In contrast to this is the backward Euler Method, which is an implicit method since\n",
    "\n",
    "$$\n",
    "U_{n+1} = U_{n} + \\Delta tf(U_{n+1}, t_{n+1}).\n",
    "$$\n",
    "\n",
    "We hence need to solve a linear or nonlinear system of equations to compute $U_{n+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of forward Euler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the model problem\n",
    "\n",
    "$$\n",
    "u'=\\alpha u\n",
    "$$\n",
    "\n",
    "for $\\alpha < 0$. Note that the explicit solution of this problem is $u(t) = u_0e^{\\alpha t}$. For $t\\rightarrow\\infty$ we have $u(t)\\rightarrow 0$ if $\\alpha < 0$.\n",
    "\n",
    "The forward Euler method can now be written as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "U_{n+1} &= (1+\\alpha\\Delta t)U_n\\\\\n",
    "        &= (1+\\alpha\\Delta t)^nU_0.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Hence, in order for the solution to decay we need that $|1+\\alpha\\Delta t| < 1$ or equivalently\n",
    "\n",
    "$$\n",
    "-1 < 1 + \\alpha \\Delta t < 1,\n",
    "$$\n",
    "\n",
    "from which we obtain $|\\alpha\\Delta t| < 2$ (if $\\alpha$ negative). Now consider the problem\n",
    "\n",
    "$$\n",
    "\\frac{dU}{dt} = AU\n",
    "$$\n",
    "\n",
    "with $A\\in\\mathbb{R}^{n\\times n}$ diagonalizable. For any eigenpair $(\\lambda, \\hat{U})$ of $A$ satisfying $A\\hat{U} = \\lambda\\hat{U}$ the function $U(t) = e^{\\lambda t}\\hat{U}$ is a solution for this problem.\n",
    "Therefore, for forward Euler to converge we require that\n",
    "\n",
    "$$\n",
    "\\Delta t < \\frac{2}{|\\lambda_{max}(A)|},\n",
    "$$\n",
    "\n",
    "where $\\lambda_{max}$ is the largest eigenvalue by magnitude.\n",
    "\n",
    "As example let us take a look at the problem\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u(x, t)}{\\partial t} = \\frac{\\partial^2 u(x, t)}{\\partial x^2}\n",
    "$$\n",
    "\n",
    "with $u(x, 0) = u_0(x)$, $u(0, t) = u(1, t) = 0$. We can discretise the right-hand side using our usual second order finite dfference scheme. For the left-hand side, we use the forward Euler method. This gives us the recurrence equation\n",
    "\n",
    "$$\n",
    "U_{n+1} = U_n + \\Delta t A U_n,\n",
    "$$\n",
    "\n",
    "with $A = \\frac{1}{h^2}\\text{tridiag}(1, -2, 1)$.\n",
    "\n",
    "The eigenvalues of $A$ are given explicitly as\n",
    "\n",
    "$$\n",
    "\\lambda_k = -\\frac{1}{h^2}4\\sin^2\\frac{k\\pi}{2(n+1)}\n",
    "$$\n",
    "\n",
    "We therefore have that $|\\lambda_{max}|\\sim \\frac{4}{h^2}$. Hence, for forward Euler to be stable we require that\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta t}{h^2} \\lesssim \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "Hence, we need that $\\Delta t\\sim h^2$, meaning that the number of required time steps grows qudratically with the discretisation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of backward Euler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For backward Euler we obtain\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "U_{n+1} &= (1-\\alpha\\Delta t)^{-1}U_n\\\\\n",
    "        &= (1-\\alpha\\Delta t)^{-n}U_0.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We now require that $|(1-\\alpha \\Delta t)^{-1}| < 1$. But for $\\alpha>0$ this is always true. Hence, the backward Euler method is unconditionally stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit vs explicit methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is very typical. In computational sciences we always have to make a choice between implicit and explicit methods. The advantage of implicit methods are the very good stability properties, allowing us for the backward Euler method to choose the time-discretisation independent of the spatial discretisation. For explicit methods we have to be much more careful and in the case of Euler we have the quadratic dependency between time-steps and spatial discretisation. However, a single time-step is much cheaper for explicit Euler as we do not need to solve a linear or nonlinear system of equations in each step. The right choice of solver depends on a huge number of factors and is very application dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Stepping Methods in Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice we do not necesarily use explicit or implicit Euler. There are many better methods out there. The Scipy library provides a number of time-stepping algorithms. For PDE problems PETSc has an excellent infrastructure of time-stepping methods built in to support the solution of time-dependent PDEs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev] *",
   "language": "python",
   "name": "conda-env-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# LSA Assignment 3 - Sparse matrices

This assignment makes up 30% of the overall marks for the course. The deadline for submitting this assignment is **5pm on Friday 1 September 2023**.

Coursework is to be submitted using the link on Moodle. You should submit a single pdf file containing your code, the output when you run your code, and your answers
to any text questions included in the assessment. The easiest ways to create this file are:

- Write your code and answers in a Jupyter notebook, then select File -> Download as -> PDF via LaTeX (.pdf).
- Write your code and answers on Google Colab, then select File -> Print, and print it as a pdf.

Tasks you are required to carry out and questions you are required to answer are shown in bold below.

## The assignment

### Part 1: Comparing sparse and dense matrices
For a collection of sparse matrices of your choice and a random vector, **measure the time taken to perform a `matvec` product**.
You should use Scipy to store the sparse matrix is the most suitable format.
Convert the same matrices to Numpy dense matrices and **measure the time taken to compute a dense matrix-vector product using Numpy**.
**Create a plot showing the times of the sparse and dense for a range of matrix sizes** and
**briefly (1-2 sentence) comment on what your plot shows**.

For a matrix of your choice and a random vector, **use Scipy's `gmres` and `cg` sparse solvers to solve a matrix problem using your CSR matrix**.
Check if the two solutions obtained are the same. 
**Briefly comment (1-2 sentences) on why the solutions are or are not the same (or are nearly but not exactly the same).**

### Part 2: Implementing a custom matrix
The following code snippet shows how you can define your own matrix-like operator.

```
from scipy.sparse.linalg import LinearOperator


class CSRMatrix(LinearOperator):
    def __init__(self, coo_matrix):
        self.shape = coo_matrix.shape
        self.dtype = coo_matrix.dtype
        # You'll need to put more code here

    def _matvec(self, vector):
        """Compute a matrix-vector product."""
        pass
```

Let $\mathrm{A}$ by a $n+1$ by $n+1$ matrix with the following structure:

- The top left $n$ by $n$ block of $\mathrm{A}$ is a diagonal matrix
- The bottom right entry is 0

In other words, $\mathrm{A}$ looks like this, where $*$ represents a non-zero value

$$
\mathrm{A}=\begin{pmatrix}
*&0&0&\cdots&0&\hspace{3mm}*\\
0&*&0&\cdots&0&\hspace{3mm}*\\
0&0&*&\cdots&0&\hspace{3mm}*\\
\vdots&\vdots&\vdots&\ddots&0&\hspace{3mm}\vdots\\
0&0&0&\cdots&*&\hspace{3mm}*\\[3mm]
*&*&*&\cdots&*&\hspace{3mm}0\\
\end{pmatrix}
$$

**Implement a Scipy `LinearOperator` for matrices of this form**. Your implementation must include a matrix-vector product (`matvec`) and the shape of the matrix (`self.shape`).
In your implementation of `matvec`, you should be careful to ensure that the product does not have more computational complexity then necessary.

For a range of values of $n$, **create matrices in your format where each entry is a random number**.
For each of these matrices, **compute matrix-vector products using your implementation and measure the time taken to compute these**.
Create an alternative version of each matrix, stored using a Scipy or Numpy format of your choice,
and **measure the time taken to compute matrix-vector products using this format**. **Make a plot showing time taken against $n$**.
**Comment (2-4 sentences) on what your plot shows, and why you think one of these methods is faster than the other** (or why they take the same amount of time if this is the case).
